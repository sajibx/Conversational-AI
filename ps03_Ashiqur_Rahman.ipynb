{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install NLTK\n",
        "!pip install nltk\n",
        "\n",
        "# Step 2: Import the necessary functions\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "# Step 3: Define the text\n",
        "text = \"Natural language processing is a field of artificial intelligence. It focuses on the interaction between computers and human language. The goal is to enable computers to understand, interpret, and generate human language. NLP is used in many applications, such as chatbots and machine translation.\"\n",
        "\n",
        "# Step 4: Download NLTK data for tokenization\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Step 5: Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Step 6: Print the tokens\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# Step 7: Count the number of tokens\n",
        "print(\"Number of tokens:\", len(tokens))\n",
        "\n",
        "# Step 8: Calculate the frequency of each token\n",
        "freq_dist = FreqDist(tokens)\n",
        "print(\"Token Frequencies:\", freq_dist)\n",
        "\n",
        "# Step 9: Display token frequency in detail\n",
        "for token, frequency in freq_dist.items():\n",
        "    print(f\"{token}: {frequency}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAbQht1tY64z",
        "outputId": "455330cc-2328-46ff-f609-f964e84d4772"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['Natural', 'language', 'processing', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', '.', 'It', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'human', 'language', '.', 'The', 'goal', 'is', 'to', 'enable', 'computers', 'to', 'understand', ',', 'interpret', ',', 'and', 'generate', 'human', 'language', '.', 'NLP', 'is', 'used', 'in', 'many', 'applications', ',', 'such', 'as', 'chatbots', 'and', 'machine', 'translation', '.']\n",
            "Number of tokens: 51\n",
            "Token Frequencies: <FreqDist with 37 samples and 51 outcomes>\n",
            "Natural: 1\n",
            "language: 3\n",
            "processing: 1\n",
            "is: 3\n",
            "a: 1\n",
            "field: 1\n",
            "of: 1\n",
            "artificial: 1\n",
            "intelligence: 1\n",
            ".: 4\n",
            "It: 1\n",
            "focuses: 1\n",
            "on: 1\n",
            "the: 1\n",
            "interaction: 1\n",
            "between: 1\n",
            "computers: 2\n",
            "and: 3\n",
            "human: 2\n",
            "The: 1\n",
            "goal: 1\n",
            "to: 2\n",
            "enable: 1\n",
            "understand: 1\n",
            ",: 3\n",
            "interpret: 1\n",
            "generate: 1\n",
            "NLP: 1\n",
            "used: 1\n",
            "in: 1\n",
            "many: 1\n",
            "applications: 1\n",
            "such: 1\n",
            "as: 1\n",
            "chatbots: 1\n",
            "machine: 1\n",
            "translation: 1\n"
          ]
        }
      ]
    }
  ]
}